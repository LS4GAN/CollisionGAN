{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cycle GAN\n",
    "A simpler CycleGAN follow [this repo](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix).\n",
    "\n",
    "Modify it to handle the single-channeled TPC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "# from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "util_path = '/sdcc/u/yhuang2/PROJs/GAN/yi_CycleGAN/utils'\n",
    "assert Path(util_path).exists()\n",
    "if util_path not in sys.path:\n",
    "    sys.path.append(util_path)\n",
    "from network import ImagePool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model_path = '/sdcc/u/yhuang2/PROJs/GAN/yi_CycleGAN/models'\n",
    "assert Path(model_path).exists()\n",
    "if model_path not in sys.path:\n",
    "    sys.path.append(model_path)\n",
    "from resnet import ResnetGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_G(\n",
    "    input_nc,\n",
    "    output_nc,\n",
    "    ngf,\n",
    "    netG,\n",
    "    norm_type='instance', \n",
    "    use_dropout=False\n",
    "):\n",
    "    \n",
    "    \"\"\"\n",
    "    Create a generator:\n",
    "    \n",
    "    Parameters:\n",
    "        1. input_nc (int): number of input channels\n",
    "        2. output_nc (int): number of output channels\n",
    "        3. ngf (int): base number of filters in the conv layers\n",
    "        4. netG (str), the architecture's name: resnet_9blocks | resnet_6blocks \n",
    "            (I will implement remaining later),\n",
    "        5. norm_type (str): the name of the normalization: instance | batch | none\n",
    "        6. use_dropout (bool): whether to use dropout.\n",
    "    \n",
    "    Returns: A generator\n",
    "    \"\"\"\n",
    "    \n",
    "    net = None,\n",
    "    norm_layer = get_norm_layer(norm_type=norm_type)\n",
    "    \n",
    "    if netG == 'resent_9blocks':\n",
    "        net = ResnetGenerator(\n",
    "            input_nc, \n",
    "            output_nc, \n",
    "            ngf, \n",
    "            norm_layer=norm_layer, \n",
    "            use_dropout=use_dropout,\n",
    "            n_blocks=9\n",
    "        )\n",
    "    elif netG == 'resnet_6blocks':\n",
    "        net = ResnetGenerator(\n",
    "            input_nc, \n",
    "            output_nc, \n",
    "            ngf, \n",
    "            norm_layer=norm_layer, \n",
    "            use_dropout=use_dropout,\n",
    "            n_blocks=6\n",
    "        )\n",
    "    else:\n",
    "        raise NotImplementedError(f'Generator model name {netG} is not implemented')\n",
    "    \n",
    "    return init_weights(net)\n",
    "\n",
    "\n",
    "def define_D(\n",
    "    input_nc, \n",
    "    ndf,\n",
    "    netD,\n",
    "    n_layer=3,\n",
    "    norm_type='instance',\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a discriminator\n",
    "\n",
    "    Parameters:\n",
    "        1. input_nc (int): number of channels in input images\n",
    "        2. ndf (int): number of filters in the first conv layer\n",
    "        3. netD (str): the architecture's name: basic | n_layers | pixel\n",
    "        4.n_layers_D (int): the number of conv layers in the discriminator; \n",
    "            effective when netD=='n_layers'\n",
    "        5. norm_type (str): the type of normalization layers used in the network.\n",
    "\n",
    "    Returns: A discriminator\n",
    "    \"\"\"\n",
    "    \n",
    "    norm_layer = get_norm_layer(norm_type=norm_type)\n",
    "    net = NLayerDiscriminator(input_nc, ndf, n_layers=n_layers, norm_layer=norm_layer)\n",
    "    return init_weight(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CycleGAN(nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(CycleGAN, self).__init__()\n",
    "        # model and loss names\n",
    "        self.model_names = ['G_A', 'G_B', 'D_A', 'D_B']\n",
    "        self.loss_names = [\n",
    "            'D_A', # GAN adversarial loss at the discriminator D_A\n",
    "            'G_A', # GAN adversarial loss at the generator G_A\n",
    "            'cycle_A', # cycle loss at domain A\n",
    "            'idt_A', # identity loss at domain A\n",
    "            'D_B', # GAN adversarial loss at the discriminator D_B\n",
    "            'G_B', # GAN adversarial loss at the generator G_B\n",
    "            'cycle_B', # cycle loss at domain B\n",
    "            'idt_B', # identity loss at domain B\n",
    "        ]\n",
    "        # generator networks\n",
    "        self.netG_A = define_G(\n",
    "            opt.input_nc,\n",
    "            opt.output_nc,\n",
    "            opt.ngf,\n",
    "            opt.netG,\n",
    "            opt.norm_type,\n",
    "            opt.use_dropout\n",
    "        )\n",
    "        self.netG_B = define_G(\n",
    "            opt.output_nc,\n",
    "            opt.input_nc, \n",
    "            opt.ngf,\n",
    "            opt.netG,\n",
    "            opt.norm_type,\n",
    "            opt.use_dropout\n",
    "        )\n",
    "        \n",
    "        # discriminator networks, criterions, and optimizers for training\n",
    "        if opt.isTrain:\n",
    "            self.netD_A = define_D(\n",
    "                opt.output_nc,\n",
    "                opt.ndf, # number of discriminator filters in the first conv layer\n",
    "                opt.netD,\n",
    "                opt.n_layers_D,\n",
    "                opt.norm_type,\n",
    "            )\n",
    "            self.netD_B = define_D(\n",
    "                opt.input_nc,\n",
    "                opt.ndf, # number of discriminator filters in the first conv layer\n",
    "                opt.netD,\n",
    "                opt.n_layers_D,\n",
    "                opt.norm_type,\n",
    "            )\n",
    "            \n",
    "            if opt.lambda_identity > 0:\n",
    "                assert(opt.input_nc == opt.output_nc)\n",
    "            \n",
    "            # fake images buffers\n",
    "            self.fake_A_pool = ImagePool(opt.pool_size)\n",
    "            self.fake_B_pool = ImagePool(opt.pool_size)\n",
    "            \n",
    "            # Loss functions\n",
    "            self.criterionGAN = GANLoss(opt.gan_mode)\n",
    "            self.criterionCycle = torch.nn.L1Loss()\n",
    "            self.criterionIdt = torch.nn.L1Loss()\n",
    "            \n",
    "            # Optimizers\n",
    "            self.optimizer_G = torch.optim.Adam(\n",
    "                itertools.chain(self.netG_A.parameters(), self.netG_B.parameters()), \n",
    "                lr=opt.lr, \n",
    "                betas=(opt.beta1, .999)\n",
    "            )\n",
    "            self.optimizer_D = torch.optim.Adam(\n",
    "                itertools.chain(self.netD_A.parameters(), self.netD_B.parameters()), \n",
    "                lr=opt.lr, \n",
    "                betas=(opt.beta1, .999)\n",
    "            )\n",
    "            self.optimizers = [self.optimizer_G, self.optimizer_D]\n",
    "            self.schedulers = [\n",
    "                network.get_scheduler(\n",
    "                    optimizer, \n",
    "                    lr_policy=opt.lr_policy, \n",
    "                    n_epochs_no_decay=opt.n_epochs_no_decay, \n",
    "                    n_epochs_decay=opt.n_epochs_decay, \n",
    "                    lr_decay_steps=opt.lr_decay_steps\n",
    "                )\n",
    "                for optimizer in self.optimizer\n",
    "            ]\n",
    "       \n",
    "    \n",
    "    def set_input(self, input):\n",
    "        self.real_A = input['A']\n",
    "        self.real_B = input['B']\n",
    "        self.image_paths = input['A_paths']\n",
    "        \n",
    "    \n",
    "    def forward(self):\n",
    "        self.fake_B = self.netG_A(self.real_A) # G_A(A)\n",
    "        self.rec_A = self.netG_B(self.fake_B)  # G_B(G_A(A))\n",
    "        self.fake_A = self.netG_B(self.real_B) # G_B(B)\n",
    "        self.rec_B = self.netG_A(self.fake_A)  # G_A(G_B(B))\n",
    "        \n",
    "        \n",
    "    def backward_D_basic(self, netD, real, fake):\n",
    "        \"\"\"\n",
    "        Calculate GAN loss for the discriminator\n",
    "        \n",
    "        Parameters:\n",
    "            1. netD (network): the discriminator D\n",
    "            2. real (tensor): real images\n",
    "            3. fake (tensor): images generated by a generator\n",
    "        \n",
    "        Retrun:\n",
    "            the discriminator loss.\n",
    "        \"\"\"\n",
    "        # Real\n",
    "        loss_D_real = self.criterionGAN(netD(real), True)\n",
    "        \n",
    "        # Fake\n",
    "        loss_D_fake = self.criterionGAN(netD(fake.detach()), False)\n",
    "        \n",
    "        # Combine loss and calculate gradients\n",
    "        loss_D = (loss_D_real + loss_D_fake) * .5\n",
    "        loss_D.backward()\n",
    "        \n",
    "        return loss_D\n",
    "    \n",
    "    def backward_D_A(self):\n",
    "        \"\"\"\n",
    "        Calculate GAN loss for the discriminator D_A\n",
    "        \"\"\"\n",
    "        self.loss_D_A = self.backward_D_basic(\n",
    "            self.netD_A,\n",
    "            self.real_B,\n",
    "            # the collection of fake images is a \n",
    "            # mixture of old and new fake images\n",
    "            self.fake_B_pool.query(self.fake_B)\n",
    "        )\n",
    "    \n",
    "    def backward_D_B(self):\n",
    "        \"\"\"\n",
    "        Calculate GAN loss for the discriminator D_B\n",
    "        \"\"\"\n",
    "        self.loss_D_B = self.backward_D_basic(\n",
    "            self.netD_B,\n",
    "            self.real_A,\n",
    "            # the collection of fake images is a \n",
    "            # mixture of old and new fake images\n",
    "            self.fake_A_pool.query(self.fake_A)\n",
    "        )\n",
    "        \n",
    "    def backward_G(self):\n",
    "        \"\"\"\n",
    "        Calculate the loss for generators G_A and G_B\n",
    "        \"\"\"\n",
    "        lambda_idt = self.opt.lambda_identity # it is a multplier to lambda_A and lambda_B\n",
    "        lambda_A, lambda_B = self.opt.lambda_A, self.opt.lambda_B\n",
    "        \n",
    "        # Identity loss\n",
    "        self.loss_idt_A, self.loss_idt_B = 0, 0\n",
    "        if lambda_idt > 0:\n",
    "            self.idt_A = self.netG_A(self.real_B)\n",
    "            self.loss_idt_A = self.criterionIdt(self.idt_A, self.real_B) * lambda_B * lambda_idt\n",
    "            self.idt_B = self.netG_B(self.real_A)\n",
    "            self.loss_idt_B = self.criterionIdt(self.idt_B, self.real_A) * lambda_A * lambda_idt\n",
    "        \n",
    "        # GAN losses\n",
    "        self.loss_G_A = self.criterionGAN(self.netD_A(self.fake_B), True)\n",
    "        self.loss_G_A = self.criterionGAN(self.netD_B(self.fake_A), True)\n",
    "        \n",
    "        # Cycle losses:\n",
    "        self.loss_cycle_A = self.criterionCycle(self.rec_A, self.real_A) * lambda_A\n",
    "        self.loss_cycle_B = self.criterionCycle(self.rec_B, self.real_B) * lambda_B\n",
    "        \n",
    "        # Combine and backpropagate\n",
    "        self.loss_G = self.loss_G_A + self.loss_G_B \\\n",
    "                    + self.loss_cycle_A + self.loss_cycle_B \\\n",
    "                    + self.loss_idt_A + self.loss_idt_B\n",
    "        self.loss_G.backward()\n",
    "        \n",
    "    def optimize_parameters(self):\n",
    "        \"\"\"\n",
    "        Calculate losses and gradients, and update network weights.\n",
    "        \"\"\"\n",
    "        self.forward()\n",
    "        \n",
    "        # Optimize generators\n",
    "        for net in [self.netD_A, self.netD_B]:\n",
    "            for param in net.parameters():\n",
    "                param.requires_grad = False\n",
    "        self.optimizer_G.zero_grad()\n",
    "        self.backward_G()\n",
    "        self.optimizer_G.step()\n",
    "        \n",
    "        # Optimize discriminators\n",
    "        for net in [self.netD_A, self.netD_B]:\n",
    "            for param in net.parameters():\n",
    "                param.requires_grad = False\n",
    "        self.optimizer_D.zero_grad()\n",
    "        self.backward_D_A()\n",
    "        self.backward_D_B()\n",
    "        self.optimizer_D.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yi_test",
   "language": "python",
   "name": "yi_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
