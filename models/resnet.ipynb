{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_conv_block(dim, padding_type, norm_layer, use_dropout, use_bias):\n",
    "    \"\"\"\n",
    "    Construct a convolutional block\n",
    "    Parameters:\n",
    "        dim (int) -- the number of channels in the conv layer.\n",
    "        padding_type (str) -- the type of padding layer: reflect | replicate | zero\n",
    "        norm_layer -- normalization layer\n",
    "        use_dropout (bool) -- whether to use dropout layers\n",
    "        use_bias (bool) -- whether use bias in the conv layers\n",
    "\n",
    "    Return a conv block (with a conv layer, a normalization layer, and a non-lineary layer(ReLU))\n",
    "    \"\"\"\n",
    "    conv_block = []\n",
    "    p = 0\n",
    "    if padding_type == 'reflect':\n",
    "        conv_block.append(nn.ReflectionPad2d(1))\n",
    "    elif padding_type == 'replicate':\n",
    "        conv_block.append(nn.ReplicationPad2d(1))\n",
    "    elif padding_type == 'zero':\n",
    "        p = 1\n",
    "    else:\n",
    "        raise NotImplementedError(f'padding {padding_type} is not implemented')\n",
    "\n",
    "    conv_block += [\n",
    "        nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias),\n",
    "        norm_layer(dim),\n",
    "        nn.ReLU(True)\n",
    "    ]\n",
    "    if use_dropout:\n",
    "        conv_block.append(nn.Dropout(.5))\n",
    "\n",
    "    p = 0\n",
    "    if padding_type == 'reflect':\n",
    "        conv_block.append(nn.ReflectionPad2d(1))\n",
    "    elif padding_type == 'replicate':\n",
    "        conv_block.append(nn.ReplicationPad2d(1))\n",
    "    elif padding_type == 'zero':\n",
    "        p = 1\n",
    "    else:\n",
    "        raise NotImplementedError(f'padding {padding_type} is not implemented')\n",
    "\n",
    "    conv_block += [\n",
    "        nn.Conv2d(dim, dim, kernel_size=3, padding=p, bias=use_bias),\n",
    "        norm_layer(dim)\n",
    "    ]\n",
    "\n",
    "    return nn.Sequential(*conv_block)\n",
    "\n",
    "\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, dim, padding_type, norm_layer, use_dropout, use_bias):\n",
    "        \"\"\"\n",
    "        Initialize the Resnet block\n",
    "        \n",
    "        A resnet block is a Conv block with skip connections.\n",
    "        We construct a Conv block with build_conv_block function,\n",
    "        and implement skip connections in <forward> functions.\n",
    "        \"\"\"\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.conv_block = build_conv_block(dim, padding_type, norm_layer, use_dropout, use_bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetGenerator(nn.Module):\n",
    "    \"\"\"\n",
    "    Resnet-based generator that consists of Resnet blocks \n",
    "    between a frew downsampling/upsampling operation.\n",
    "    We adapt Torch code and idea from Justin Johnson's neural style transfer project\n",
    "    (https://github.com/jcjohnson/fast-neural-style).\n",
    "    \n",
    "    Width and height of size 4k are preserved.\n",
    "    Width and height of size 4k + i, i = 1, 2, 3, will be mapped to 4(k + 1).  \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        input_nc, \n",
    "        output_nc,\n",
    "        ngf=64,\n",
    "        norm_layer=nn.BatchNorm2d,\n",
    "        n_blocks=6, \n",
    "        padding_type='reflect',\n",
    "        use_dropout=False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Construct a Resnet-based Generator\n",
    "        Parameters:\n",
    "            input_nc (int) -- the number of channels in the input\n",
    "            output_nc (int) -- the number of channels in the output\n",
    "            ngf (int) -- the number of filters in the leading conv layer\n",
    "            norm_layer (torch layer) -- normalization layer\n",
    "            n_blocks (int) -- the number of ResNet blocks\n",
    "            padding_type (str) -- the type of padding layer in conv layers: reflect | replicate | zero\n",
    "            use_dropout (bool) -- whether use dropout layers in the ResNet blocks\n",
    "        \"\"\"\n",
    "        \n",
    "        assert(n_blocks > 0), \"n_blocks must be greater than zero!\"\n",
    "        super(ResnetGenerator, self).__init__()\n",
    "        \n",
    "        if :\n",
    "            use_bias =  (type(norm_layer) == functools.partial) norm_layer.func == nn.InstanceNorm2d\n",
    "        else:\n",
    "            use_bias = norm_layer == nn.InstanceNorm2d\n",
    "        \n",
    "        # Add leading layers\n",
    "        model = [\n",
    "            nn.ReflectionPad2d(3), # padding=3\n",
    "            nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0, bias=use_bias),\n",
    "            norm_layer(ngf),\n",
    "            nn.ReLU(True) # Inplace\n",
    "        ]\n",
    "        \n",
    "        # Add downsampling layers\n",
    "        n_downsamplings = 2\n",
    "        mult = 1\n",
    "        for i in range(n_downsamplings):\n",
    "            ic, oc = ngf * mult, ngf * mult * 2\n",
    "            mult *= 2\n",
    "            model += [\n",
    "                # @Yi pay attention to this padding\n",
    "                nn.Conv2d(ic, oc, kernel_size=3, stride=2, padding=1, bias=use_bias),\n",
    "                norm_layer(oc),\n",
    "                nn.ReLU(True)\n",
    "            ]\n",
    "        \n",
    "        # Add ResNet blocks\n",
    "        for i in range(n_blocks):\n",
    "            model.append(\n",
    "                ResnetBlock(\n",
    "                    ngf * mult, \n",
    "                    padding_type=padding_type, \n",
    "                    norm_layer=norm_layer, \n",
    "                    use_dropout=use_dropout,\n",
    "                    use_bias=use_bias\n",
    "                )\n",
    "            )\n",
    "            \n",
    "        # Add upsampling layers\n",
    "        for i in range(n_downsamplings):\n",
    "            ic, oc = ngf * mult, ngf * mult // 2\n",
    "            mult //= 2\n",
    "            model += [\n",
    "                # @Yi pay attention to the padding and output_padding here\n",
    "                nn.ConvTranspose2d(\n",
    "                    ic, oc, \n",
    "                    kernel_size=3, stride=2, \n",
    "                    padding=1, output_padding=1, \n",
    "                    bias=use_bias),\n",
    "                norm_layer(oc),\n",
    "                nn.ReLU(True)\n",
    "            ]\n",
    "        \n",
    "        model.append(nn.ReflectionPad2d(3))\n",
    "        model.append(nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0))\n",
    "        model.append(nn.Tanh())\n",
    "        \n",
    "        self.model = nn.Sequential(*model)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial\n",
    "1. Width and height of size $4k$ are preserved.\n",
    "2. Width and height of size $4k + i$, $i = 1, 2, 3$, will be mapped to $4(k + 1)$.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160: 160\n",
      "161: 164\n",
      "162: 164\n",
      "163: 164\n",
      "164: 164\n",
      "165: 168\n",
      "166: 168\n",
      "167: 168\n",
      "168: 168\n",
      "169: 172\n",
      "170: 172\n",
      "171: 172\n",
      "172: 172\n",
      "173: 176\n",
      "174: 176\n",
      "175: 176\n",
      "176: 176\n",
      "177: 180\n",
      "178: 180\n",
      "179: 180\n",
      "180: 180\n",
      "181: 184\n",
      "182: 184\n",
      "183: 184\n",
      "184: 184\n",
      "185: 188\n",
      "186: 188\n",
      "187: 188\n",
      "188: 188\n",
      "189: 192\n",
      "190: 192\n",
      "191: 192\n",
      "192: 192\n",
      "193: 196\n",
      "194: 196\n",
      "195: 196\n",
      "196: 196\n",
      "197: 200\n",
      "198: 200\n",
      "199: 200\n",
      "200: 200\n",
      "201: 204\n",
      "202: 204\n",
      "203: 204\n",
      "204: 204\n",
      "205: 208\n",
      "206: 208\n",
      "207: 208\n",
      "208: 208\n",
      "209: 212\n"
     ]
    }
   ],
   "source": [
    "for w in range(160, 210):\n",
    "    input_shape = [w, w]\n",
    "    x = torch.rand(1, 1, *input_shape, dtype=torch.float32)\n",
    "    resnet = ResnetGenerator(1, 1)\n",
    "    \n",
    "    shape = resnet(x).shape[3]\n",
    "    print(f'{w}: {shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yi_test",
   "language": "python",
   "name": "yi_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
