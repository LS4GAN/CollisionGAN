{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNetCAMD(nn.Module):\n",
    "    def __init__(self, input_channels=3, **kwargs):\n",
    "        super(AlexNetCAMD, self).__init__(**kwargs)\n",
    "        self.base_net = nn.Sequential(\n",
    "            nn.BatchNorm2d(input_channels),\n",
    "\n",
    "            nn.Conv2d(input_channels, 96, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(2, stride=2),\n",
    "\n",
    "            nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(2, stride=2),\n",
    "\n",
    "            nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Linear(384, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.base_net(x)\n",
    "        z = torch.mean(y, dim=(2, 3), keepdim=False) # Global average\n",
    "        return self.classifier(z)\n",
    "\n",
    "    def get_cam(self, x):\n",
    "        y = self.base_net(x)\n",
    "        maps = []\n",
    "        for class_weights in self.classifier.weight:\n",
    "            # y             : (N, C_o, W_o, H_o)\n",
    "            # class_weights : (C_o, )\n",
    "            # class_map     : (N, W_o, H_o)\n",
    "            class_map = torch.tensordot(y, class_weights, dims=([1,], [0,]))\n",
    "\n",
    "            # class_map : (N, W_o, H_o) -> (N, 1, W_i, H_i)\n",
    "            class_map = nn.functional.interpolate(\n",
    "                torch.unsqueeze(class_map, 1),\n",
    "                (x.shape[2], x.shape[3]),\n",
    "                mode='bilinear'\n",
    "            )\n",
    "            maps.append(class_map)\n",
    "\n",
    "        return maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial(model, input_shape, cuda=True):\n",
    "    x = torch.rand(16, 1, *input_shape, dtype=torch.float32)\n",
    "    if cuda:\n",
    "        model = model.cuda()\n",
    "        x = x.cuda()\n",
    "\n",
    "    y = model.forward(x)\n",
    "    print(f'Output shape:\\n\\t{y.shape}\\n')\n",
    "\n",
    "    num_parameters_trainable = sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
    "    num_parameters = sum([p.numel() for p in model.parameters()])\n",
    "    print(f'Number of parameters:\\n\\tTrainable = {num_parameters_trainable}\\n\\tTotal = {num_parameters}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape:\n",
      "\ttorch.Size([16, 2])\n",
      "\n",
      "Number of parameters:\n",
      "\tTrainable = 4158020\n",
      "\tTotal = 4158020\n"
     ]
    }
   ],
   "source": [
    "discriminator = AlexNetCAMD(input_channels=1)\n",
    "input_shape = [128, 128]\n",
    "trial(discriminator, input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Dataset_ls4gan(Dataset):\n",
    "#     \"\"\"\n",
    "#     LS4GAN dataset\n",
    "#     \"\"\"\n",
    "#     def __init__(self, class_paths, num_samples=None):\n",
    "#         super(Dataset_ls4gan, self).__init__()    \n",
    "#         self.image_fnames = []\n",
    "#         self.labels = []\n",
    "#         for c, class_path in enumerate(class_paths):\n",
    "#             fnames = list(Path(class_path).glob('*npz'))\n",
    "#             self.image_fnames += fnames\n",
    "#             self.labels += [c] * len(fnames)\n",
    "#         indices = np.arange(len(self.image_fnames))\n",
    "#         np.random.shuffle(indices)\n",
    "#         if num_samples is not None:\n",
    "#             indices = indices[:num_samples]\n",
    "        \n",
    "#         self.image_fnames = np.array(self.image_fnames)[indices]\n",
    "#         self.labels = np.array(self.labels)[indices]\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.image_fnames)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         image_fname, label = self.image_fnames[idx], self.labels[idx]\n",
    "        \n",
    "#         image = np.load(image_fname)\n",
    "#         key = list(image.keys())[0]\n",
    "#         image = image[key]\n",
    "#         image = np.expand_dims(np.float32(image), 0)\n",
    "        \n",
    "#         image_tensor = torch.from_numpy(image)\n",
    "#         label_tensor = torch.tensor(label, dtype=torch.int64)\n",
    "#         return image_tensor, label_tensor\n",
    "\n",
    "\n",
    "# path_base = '/sdcc/u/yhuang2/PROJs/GAN/datasets/ls4gan/toyzero_cropped'\n",
    "# dataset = 'toyzero_2021-06-29_safi_'\n",
    "\n",
    "# layer = 'W'\n",
    "\n",
    "# class_paths_train = [\n",
    "#     f'{path_base}/{dataset}{layer}/trainA/',\n",
    "#     f'{path_base}/{dataset}{layer}/trainB/'\n",
    "# ]\n",
    "\n",
    "# class_paths_test = [\n",
    "#     f'{path_base}/{dataset}{layer}/testA/',\n",
    "#     f'{path_base}/{dataset}{layer}/testB/'\n",
    "# ]\n",
    "\n",
    "\n",
    "# num_samples, bsz = 2000, 16\n",
    "\n",
    "# dataset_train = Dataset_ls4gan(class_paths_train, num_samples=num_samples)\n",
    "# dataset_test = Dataset_ls4gan(class_paths_test, num_samples=num_samples)\n",
    "# dataset_test_d = Dataset_ls4gan(class_paths_test_d)\n",
    "\n",
    "# train_loader = DataLoader(dataset_train, batch_size=bsz, shuffle=True)\n",
    "# test_loader = DataLoader(dataset_test, batch_size=bsz, shuffle=True)\n",
    "# test_loader_d = DataLoader(dataset_test_d, batch_size=bsz, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_ls4gan(Dataset):\n",
    "    \"\"\"\n",
    "    LS4GAN dataset\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        data_path, \n",
    "        window_fname, \n",
    "        num_samples=None,\n",
    "        apa=None,   # If not None, must be list \n",
    "        planes=None, # If not None, must be list, too,\n",
    "        valid_fraction=.2,\n",
    "        batch_size=32,\n",
    "    ):\n",
    "        super(Dataset_ls4gan, self).__init__()\n",
    "        df_window = pd.read_csv(window_fname, index_col=0)\n",
    "        \n",
    "        # select\n",
    "        if apa is not None:\n",
    "            df_window = df_window[df_window.apa.isin(apa)]\n",
    "        if planes is not None:\n",
    "            df_window = df_window[df_window.plane.isin(planes)]\n",
    "        if num_samples is not None and num_samples < len(df_window):\n",
    "            df_window = df_window.sample(n=num_samples // 2 , replace=False).reset_index(drop=True)\n",
    "            \n",
    "        # check existence of folders\n",
    "        assert Path(data_path).exists(), f\"{data_path} doesn't exist\"\n",
    "        fake_path = Path(data_path)/'fake'\n",
    "        real_path = Path(data_path)/'real'\n",
    "        assert fake_path.exists(), f\"{data_path} doesn't contain a subfolder called fake\"\n",
    "        assert fake_path.exists(), f\"{data_path} doesn't contain a subfolder called real\"\n",
    "        \n",
    "        # Load data\n",
    "        data_train, data_valid = [], []\n",
    "        for P, c in zip([fake_path, real_path], [0, 1]):\n",
    "            print(f'loading files from {P}')\n",
    "            for index, row in df_window.iterrows():\n",
    "                image, bkg = row['image'], row['bkg']\n",
    "                x, y, x_ws, y_ws = row['x'], row['y'], row['width'], row['height']\n",
    "                image_fname = P/image\n",
    "                image = self._load_image(image_fname, x, y, x_ws, y_ws, bkg)\n",
    "                \n",
    "                rnd_key = np.random.rand()\n",
    "                if rnd_key < valid_fraction:\n",
    "                    data_valid.append([image, c])\n",
    "                else:\n",
    "                    data_train.append([image, c])\n",
    "\n",
    "        self.loader_train = DataLoader(data_train, batch_size=batch_size, shuffle=True)\n",
    "        self.loader_valid = DataLoader(data_valid, batch_size=batch_size, shuffle=True)\n",
    "        print('Done!')\n",
    "    \n",
    "    def _load_image(self, image_fname, x, y, x_ws, y_ws, bkg):\n",
    "        image = np.load(image_fname)\n",
    "        key = list(image.keys())[0]\n",
    "        image = image[key]\n",
    "        image = image[x: x + x_ws, y: y + y_ws]\n",
    "        image -= bkg\n",
    "        image = np.expand_dims(np.float32(image), 0)\n",
    "        \n",
    "        return image   \n",
    "        \n",
    "    def get_loaders(self):\n",
    "        return self.loader_train, self.loader_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading files from /hpcgpfs01/scratch/yhuang2/merged/fake\n",
      "loading files from /hpcgpfs01/scratch/yhuang2/merged/real\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "data_path = '/hpcgpfs01/scratch/yhuang2/merged'\n",
    "min_signal = 250\n",
    "window_fname = f'/hpcgpfs01/scratch/yhuang2/merged/windows_{min_signal}-128x128.csv'\n",
    "batch_size = 32\n",
    "plane = 'U'\n",
    "dl = Dataset_ls4gan(data_path, window_fname, num_samples=2000, planes=[plane], batch_size=batch_size)\n",
    "train_loader, test_loader = dl.get_loaders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator = AlexNetCAMD(input_channels=1).cuda()\n",
    "# discriminator.load_state_dict(torch.load(f'results/model_dict_{layer}.pt'))\n",
    "# discriminator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1 / 200\n",
      "\ttrain:\tloss = 0.693433, acc = 0.490706\n",
      "\ttest:\tloss = 0.691080, acc = 0.538860\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 2 / 200\n",
      "\ttrain:\tloss = 0.690659, acc = 0.586121\n",
      "\ttest:\tloss = 0.682637, acc = 0.709845\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 3 / 200\n",
      "\ttrain:\tloss = 0.673420, acc = 0.652416\n",
      "\ttest:\tloss = 0.719609, acc = 0.466321\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 4 / 200\n",
      "\ttrain:\tloss = 0.633010, acc = 0.659232\n",
      "\ttest:\tloss = 0.603231, acc = 0.725389\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 5 / 200\n",
      "\ttrain:\tloss = 0.555642, acc = 0.785006\n",
      "\ttest:\tloss = 0.553500, acc = 0.748705\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 6 / 200\n",
      "\ttrain:\tloss = 0.493438, acc = 0.817844\n",
      "\ttest:\tloss = 0.426987, acc = 0.888601\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 7 / 200\n",
      "\ttrain:\tloss = 0.441099, acc = 0.848203\n",
      "\ttest:\tloss = 0.374025, acc = 0.883420\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 8 / 200\n",
      "\ttrain:\tloss = 0.393237, acc = 0.873606\n",
      "\ttest:\tloss = 0.345336, acc = 0.893782\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 9 / 200\n",
      "\ttrain:\tloss = 0.362758, acc = 0.881041\n",
      "\ttest:\tloss = 0.309998, acc = 0.914508\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 10 / 200\n",
      "\ttrain:\tloss = 0.332160, acc = 0.890954\n",
      "\ttest:\tloss = 0.288109, acc = 0.906736\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 11 / 200\n",
      "\ttrain:\tloss = 0.306258, acc = 0.894672\n",
      "\ttest:\tloss = 0.271464, acc = 0.904145\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 12 / 200\n",
      "\ttrain:\tloss = 0.307624, acc = 0.895291\n",
      "\ttest:\tloss = 0.239715, acc = 0.932642\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 13 / 200\n",
      "\ttrain:\tloss = 0.264034, acc = 0.910161\n",
      "\ttest:\tloss = 0.241344, acc = 0.943005\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 14 / 200\n",
      "\ttrain:\tloss = 0.245007, acc = 0.912639\n",
      "\ttest:\tloss = 0.257303, acc = 0.937824\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 15 / 200\n",
      "\ttrain:\tloss = 0.232332, acc = 0.921314\n",
      "\ttest:\tloss = 0.201480, acc = 0.937824\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 16 / 200\n",
      "\ttrain:\tloss = 0.228738, acc = 0.921933\n",
      "\ttest:\tloss = 0.189122, acc = 0.940414\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 17 / 200\n",
      "\ttrain:\tloss = 0.200269, acc = 0.934325\n",
      "\ttest:\tloss = 0.168519, acc = 0.953368\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 18 / 200\n",
      "\ttrain:\tloss = 0.194216, acc = 0.934944\n",
      "\ttest:\tloss = 0.179131, acc = 0.943005\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 19 / 200\n",
      "\ttrain:\tloss = 0.185155, acc = 0.935564\n",
      "\ttest:\tloss = 0.247290, acc = 0.945596\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 20 / 200\n",
      "\ttrain:\tloss = 0.168144, acc = 0.941760\n",
      "\ttest:\tloss = 0.308154, acc = 0.950777\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 21 / 200\n",
      "\ttrain:\tloss = 0.160423, acc = 0.944858\n",
      "\ttest:\tloss = 0.154122, acc = 0.953368\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 22 / 200\n",
      "\ttrain:\tloss = 0.150909, acc = 0.948575\n",
      "\ttest:\tloss = 0.132921, acc = 0.953368\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 23 / 200\n",
      "\ttrain:\tloss = 0.148923, acc = 0.947955\n",
      "\ttest:\tloss = 0.128580, acc = 0.948187\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 24 / 200\n",
      "\ttrain:\tloss = 0.142506, acc = 0.947336\n",
      "\ttest:\tloss = 0.201337, acc = 0.950777\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 25 / 200\n",
      "\ttrain:\tloss = 0.134735, acc = 0.951673\n",
      "\ttest:\tloss = 0.111076, acc = 0.958549\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 26 / 200\n",
      "\ttrain:\tloss = 0.138370, acc = 0.946097\n",
      "\ttest:\tloss = 0.126811, acc = 0.950777\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 27 / 200\n",
      "\ttrain:\tloss = 0.125448, acc = 0.952912\n",
      "\ttest:\tloss = 0.111939, acc = 0.961140\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 28 / 200\n",
      "\ttrain:\tloss = 0.122466, acc = 0.952292\n",
      "\ttest:\tloss = 0.104967, acc = 0.955959\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 29 / 200\n",
      "\ttrain:\tloss = 0.121657, acc = 0.952292\n",
      "\ttest:\tloss = 0.108979, acc = 0.953368\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 30 / 200\n",
      "\ttrain:\tloss = 0.116476, acc = 0.957249\n",
      "\ttest:\tloss = 0.102053, acc = 0.955959\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 31 / 200\n",
      "\ttrain:\tloss = 0.115117, acc = 0.953532\n",
      "\ttest:\tloss = 0.096655, acc = 0.961140\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 32 / 200\n",
      "\ttrain:\tloss = 0.114034, acc = 0.952292\n",
      "\ttest:\tloss = 0.093439, acc = 0.955959\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 33 / 200\n",
      "\ttrain:\tloss = 0.114659, acc = 0.957249\n",
      "\ttest:\tloss = 0.095407, acc = 0.955959\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 34 / 200\n",
      "\ttrain:\tloss = 0.106717, acc = 0.958488\n",
      "\ttest:\tloss = 0.093807, acc = 0.961140\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 35 / 200\n",
      "\ttrain:\tloss = 0.109217, acc = 0.960967\n",
      "\ttest:\tloss = 0.097368, acc = 0.963731\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 36 / 200\n",
      "\ttrain:\tloss = 0.111610, acc = 0.955390\n",
      "\ttest:\tloss = 0.090891, acc = 0.958549\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 37 / 200\n",
      "\ttrain:\tloss = 0.100251, acc = 0.964064\n",
      "\ttest:\tloss = 0.083621, acc = 0.966321\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 38 / 200\n",
      "\ttrain:\tloss = 0.126301, acc = 0.949195\n",
      "\ttest:\tloss = 0.081802, acc = 0.966321\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 39 / 200\n",
      "\ttrain:\tloss = 0.103172, acc = 0.959108\n",
      "\ttest:\tloss = 0.077838, acc = 0.963731\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 40 / 200\n",
      "\ttrain:\tloss = 0.105908, acc = 0.956630\n",
      "\ttest:\tloss = 0.090583, acc = 0.963731\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 41 / 200\n",
      "\ttrain:\tloss = 0.106360, acc = 0.959727\n",
      "\ttest:\tloss = 0.076541, acc = 0.968912\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 42 / 200\n",
      "\ttrain:\tloss = 0.102264, acc = 0.958488\n",
      "\ttest:\tloss = 0.116700, acc = 0.966321\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 43 / 200\n",
      "\ttrain:\tloss = 0.093981, acc = 0.964064\n",
      "\ttest:\tloss = 0.097456, acc = 0.963731\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 44 / 200\n",
      "\ttrain:\tloss = 0.091138, acc = 0.965923\n",
      "\ttest:\tloss = 0.072253, acc = 0.966321\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 45 / 200\n",
      "\ttrain:\tloss = 0.089739, acc = 0.965304\n",
      "\ttest:\tloss = 0.070455, acc = 0.971503\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 46 / 200\n",
      "\ttrain:\tloss = 0.085538, acc = 0.966543\n",
      "\ttest:\tloss = 0.063086, acc = 0.974093\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 47 / 200\n",
      "\ttrain:\tloss = 0.087849, acc = 0.964064\n",
      "\ttest:\tloss = 0.072898, acc = 0.971503\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 48 / 200\n",
      "\ttrain:\tloss = 0.088420, acc = 0.962825\n",
      "\ttest:\tloss = 0.070168, acc = 0.971503\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 49 / 200\n",
      "\ttrain:\tloss = 0.089033, acc = 0.966543\n",
      "\ttest:\tloss = 0.074343, acc = 0.966321\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 50 / 200\n",
      "\ttrain:\tloss = 0.100559, acc = 0.961586\n",
      "\ttest:\tloss = 0.069618, acc = 0.966321\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 51 / 200\n",
      "\ttrain:\tloss = 0.089345, acc = 0.963445\n",
      "\ttest:\tloss = 0.069829, acc = 0.976684\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 52 / 200\n",
      "\ttrain:\tloss = 0.087008, acc = 0.966543\n",
      "\ttest:\tloss = 0.063895, acc = 0.971503\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 53 / 200\n",
      "\ttrain:\tloss = 0.079353, acc = 0.967162\n",
      "\ttest:\tloss = 0.075406, acc = 0.974093\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 54 / 200\n",
      "\ttrain:\tloss = 0.081629, acc = 0.970260\n",
      "\ttest:\tloss = 0.074241, acc = 0.958549\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 55 / 200\n",
      "\ttrain:\tloss = 0.081451, acc = 0.965923\n",
      "\ttest:\tloss = 0.062947, acc = 0.963731\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 56 / 200\n",
      "\ttrain:\tloss = 0.077790, acc = 0.969021\n",
      "\ttest:\tloss = 0.072360, acc = 0.974093\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 57 / 200\n",
      "\ttrain:\tloss = 0.086989, acc = 0.964684\n",
      "\ttest:\tloss = 0.067828, acc = 0.971503\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 58 / 200\n",
      "\ttrain:\tloss = 0.075597, acc = 0.969021\n",
      "\ttest:\tloss = 0.065966, acc = 0.971503\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 59 / 200\n",
      "\ttrain:\tloss = 0.087987, acc = 0.962825\n",
      "\ttest:\tloss = 0.065054, acc = 0.968912\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 60 / 200\n",
      "\ttrain:\tloss = 0.119610, acc = 0.954151\n",
      "\ttest:\tloss = 0.070377, acc = 0.968912\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 61 / 200\n",
      "\ttrain:\tloss = 0.092824, acc = 0.964064\n",
      "\ttest:\tloss = 0.052528, acc = 0.987047\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 62 / 200\n",
      "\ttrain:\tloss = 0.076521, acc = 0.973358\n",
      "\ttest:\tloss = 0.058747, acc = 0.984456\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 63 / 200\n",
      "\ttrain:\tloss = 0.078931, acc = 0.969641\n",
      "\ttest:\tloss = 0.055961, acc = 0.974093\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 64 / 200\n",
      "\ttrain:\tloss = 0.079238, acc = 0.970880\n",
      "\ttest:\tloss = 0.060217, acc = 0.968912\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 65 / 200\n",
      "\ttrain:\tloss = 0.075444, acc = 0.972739\n",
      "\ttest:\tloss = 0.057272, acc = 0.976684\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 66 / 200\n",
      "\ttrain:\tloss = 0.073131, acc = 0.970260\n",
      "\ttest:\tloss = 0.055489, acc = 0.976684\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 67 / 200\n",
      "\ttrain:\tloss = 0.069768, acc = 0.973358\n",
      "\ttest:\tloss = 0.053999, acc = 0.976684\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 68 / 200\n",
      "\ttrain:\tloss = 0.072987, acc = 0.970880\n",
      "\ttest:\tloss = 0.047666, acc = 0.984456\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 69 / 200\n",
      "\ttrain:\tloss = 0.072079, acc = 0.973358\n",
      "\ttest:\tloss = 0.055512, acc = 0.971503\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 70 / 200\n",
      "\ttrain:\tloss = 0.076638, acc = 0.970880\n",
      "\ttest:\tloss = 0.055329, acc = 0.984456\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 71 / 200\n",
      "\ttrain:\tloss = 0.072379, acc = 0.970880\n",
      "\ttest:\tloss = 0.050305, acc = 0.984456\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 72 / 200\n",
      "\ttrain:\tloss = 0.071678, acc = 0.972119\n",
      "\ttest:\tloss = 0.053777, acc = 0.981865\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 73 / 200\n",
      "\ttrain:\tloss = 0.071355, acc = 0.971499\n",
      "\ttest:\tloss = 0.048495, acc = 0.987047\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 74 / 200\n",
      "\ttrain:\tloss = 0.071909, acc = 0.975217\n",
      "\ttest:\tloss = 0.051043, acc = 0.984456\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 75 / 200\n",
      "\ttrain:\tloss = 0.067125, acc = 0.973358\n",
      "\ttest:\tloss = 0.049613, acc = 0.979275\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 76 / 200\n",
      "\ttrain:\tloss = 0.069462, acc = 0.972739\n",
      "\ttest:\tloss = 0.052316, acc = 0.979275\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 77 / 200\n",
      "\ttrain:\tloss = 0.062104, acc = 0.977076\n",
      "\ttest:\tloss = 0.045525, acc = 0.984456\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 78 / 200\n",
      "\ttrain:\tloss = 0.065115, acc = 0.972119\n",
      "\ttest:\tloss = 0.046093, acc = 0.987047\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 79 / 200\n",
      "\ttrain:\tloss = 0.082682, acc = 0.967162\n",
      "\ttest:\tloss = 0.050042, acc = 0.979275\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 80 / 200\n",
      "\ttrain:\tloss = 0.110253, acc = 0.955390\n",
      "\ttest:\tloss = 0.051420, acc = 0.981865\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 81 / 200\n",
      "\ttrain:\tloss = 0.072673, acc = 0.971499\n",
      "\ttest:\tloss = 0.067982, acc = 0.987047\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 82 / 200\n",
      "\ttrain:\tloss = 0.068764, acc = 0.973358\n",
      "\ttest:\tloss = 0.051532, acc = 0.984456\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 83 / 200\n",
      "\ttrain:\tloss = 0.062659, acc = 0.978315\n",
      "\ttest:\tloss = 0.286028, acc = 0.976684\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 84 / 200\n",
      "\ttrain:\tloss = 0.062927, acc = 0.974597\n",
      "\ttest:\tloss = 0.048444, acc = 0.987047\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 85 / 200\n",
      "\ttrain:\tloss = 0.071387, acc = 0.970880\n",
      "\ttest:\tloss = 0.056313, acc = 0.974093\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 86 / 200\n",
      "\ttrain:\tloss = 0.067998, acc = 0.972119\n",
      "\ttest:\tloss = 0.045890, acc = 0.987047\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 87 / 200\n",
      "\ttrain:\tloss = 0.064600, acc = 0.974597\n",
      "\ttest:\tloss = 0.044065, acc = 0.984456\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 88 / 200\n",
      "\ttrain:\tloss = 0.118240, acc = 0.953532\n",
      "\ttest:\tloss = 0.054772, acc = 0.979275\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 89 / 200\n",
      "\ttrain:\tloss = 0.140071, acc = 0.947336\n",
      "\ttest:\tloss = 0.061398, acc = 0.971503\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 90 / 200\n",
      "\ttrain:\tloss = 0.065180, acc = 0.976456\n",
      "\ttest:\tloss = 0.100670, acc = 0.979275\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 91 / 200\n",
      "\ttrain:\tloss = 0.063337, acc = 0.976456\n",
      "\ttest:\tloss = 0.047611, acc = 0.979275\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 92 / 200\n",
      "\ttrain:\tloss = 0.065521, acc = 0.970260\n",
      "\ttest:\tloss = 0.055851, acc = 0.974093\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 93 / 200\n",
      "\ttrain:\tloss = 0.068540, acc = 0.973358\n",
      "\ttest:\tloss = 0.071685, acc = 0.979275\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 94 / 200\n",
      "\ttrain:\tloss = 0.066200, acc = 0.976456\n",
      "\ttest:\tloss = 0.050297, acc = 0.976684\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 95 / 200\n",
      "\ttrain:\tloss = 0.062693, acc = 0.976456\n",
      "\ttest:\tloss = 0.050954, acc = 0.981865\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 96 / 200\n",
      "\ttrain:\tloss = 0.064179, acc = 0.977695\n",
      "\ttest:\tloss = 0.049957, acc = 0.976684\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 97 / 200\n",
      "\ttrain:\tloss = 0.064248, acc = 0.973358\n",
      "\ttest:\tloss = 0.043168, acc = 0.981865\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 98 / 200\n",
      "\ttrain:\tloss = 0.065112, acc = 0.975836\n",
      "\ttest:\tloss = 0.047799, acc = 0.979275\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 99 / 200\n",
      "\ttrain:\tloss = 0.061093, acc = 0.976456\n",
      "\ttest:\tloss = 0.039694, acc = 0.984456\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 100 / 200\n",
      "\ttrain:\tloss = 0.062620, acc = 0.977076\n",
      "\ttest:\tloss = 0.043047, acc = 0.987047\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 101 / 200\n",
      "\ttrain:\tloss = 0.065679, acc = 0.975836\n",
      "\ttest:\tloss = 0.042570, acc = 0.989637\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 102 / 200\n",
      "\ttrain:\tloss = 0.058249, acc = 0.979554\n",
      "\ttest:\tloss = 0.045379, acc = 0.979275\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 103 / 200\n",
      "\ttrain:\tloss = 0.059609, acc = 0.977076\n",
      "\ttest:\tloss = 0.044535, acc = 0.976684\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 104 / 200\n",
      "\ttrain:\tloss = 0.061389, acc = 0.973358\n",
      "\ttest:\tloss = 0.037765, acc = 0.987047\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 105 / 200\n",
      "\ttrain:\tloss = 0.064472, acc = 0.972739\n",
      "\ttest:\tloss = 0.044539, acc = 0.979275\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 106 / 200\n",
      "\ttrain:\tloss = 0.064828, acc = 0.973978\n",
      "\ttest:\tloss = 0.042444, acc = 0.989637\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 107 / 200\n",
      "\ttrain:\tloss = 0.055965, acc = 0.978934\n",
      "\ttest:\tloss = 0.049816, acc = 0.979275\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 108 / 200\n",
      "\ttrain:\tloss = 0.059566, acc = 0.977076\n",
      "\ttest:\tloss = 0.049486, acc = 0.976684\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 109 / 200\n",
      "\ttrain:\tloss = 0.062664, acc = 0.973358\n",
      "\ttest:\tloss = 0.042782, acc = 0.981865\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 110 / 200\n",
      "\ttrain:\tloss = 0.055602, acc = 0.977695\n",
      "\ttest:\tloss = 0.042110, acc = 0.979275\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 111 / 200\n",
      "\ttrain:\tloss = 0.058515, acc = 0.975217\n",
      "\ttest:\tloss = 0.048393, acc = 0.981865\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 112 / 200\n",
      "\ttrain:\tloss = 0.057898, acc = 0.975836\n",
      "\ttest:\tloss = 0.038214, acc = 0.979275\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 113 / 200\n",
      "\ttrain:\tloss = 0.058979, acc = 0.978315\n",
      "\ttest:\tloss = 0.049154, acc = 0.981865\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 114 / 200\n",
      "\ttrain:\tloss = 0.056434, acc = 0.978315\n",
      "\ttest:\tloss = 0.038094, acc = 0.987047\n",
      "\tlr=1.00e-05\n",
      "\n",
      "Epoch: 115 / 200\n",
      "\ttrain:\tloss = 0.056707, acc = 0.978315\n",
      "\ttest:\tloss = 0.055227, acc = 0.981865\n",
      "\tlr=5.00e-06\n",
      "\n",
      "Epoch: 116 / 200\n",
      "\ttrain:\tloss = 0.056443, acc = 0.980793\n",
      "\ttest:\tloss = 0.033557, acc = 0.989637\n",
      "\tlr=5.00e-06\n",
      "\n",
      "Epoch: 117 / 200\n",
      "\ttrain:\tloss = 0.054839, acc = 0.976456\n",
      "\ttest:\tloss = 0.041476, acc = 0.984456\n",
      "\tlr=5.00e-06\n",
      "\n",
      "Epoch: 118 / 200\n",
      "\ttrain:\tloss = 0.053948, acc = 0.979554\n",
      "\ttest:\tloss = 0.050856, acc = 0.984456\n",
      "\tlr=5.00e-06\n",
      "\n",
      "Epoch: 119 / 200\n",
      "\ttrain:\tloss = 0.059596, acc = 0.973978\n",
      "\ttest:\tloss = 0.036965, acc = 0.984456\n",
      "\tlr=5.00e-06\n",
      "\n",
      "Epoch: 120 / 200\n",
      "\ttrain:\tloss = 0.072504, acc = 0.973358\n",
      "\ttest:\tloss = 0.034710, acc = 0.984456\n",
      "\tlr=5.00e-06\n",
      "\n",
      "Epoch: 121 / 200\n",
      "\ttrain:\tloss = 0.056374, acc = 0.980174\n",
      "\ttest:\tloss = 0.030336, acc = 0.989637\n",
      "\tlr=5.00e-06\n",
      "\n",
      "Epoch: 122 / 200\n",
      "\ttrain:\tloss = 0.059017, acc = 0.978315\n",
      "\ttest:\tloss = 0.041927, acc = 0.981865\n",
      "\tlr=5.00e-06\n",
      "\n",
      "Epoch: 123 / 200\n",
      "\ttrain:\tloss = 0.054376, acc = 0.975836\n",
      "\ttest:\tloss = 0.037085, acc = 0.987047\n",
      "\tlr=5.00e-06\n",
      "\n",
      "Epoch: 124 / 200\n",
      "\ttrain:\tloss = 0.053581, acc = 0.976456\n",
      "\ttest:\tloss = 0.037338, acc = 0.984456\n",
      "\tlr=5.00e-06\n",
      "\n",
      "Epoch: 125 / 200\n",
      "\ttrain:\tloss = 0.049677, acc = 0.980793\n",
      "\ttest:\tloss = 0.833725, acc = 0.981865\n",
      "\tlr=5.00e-06\n",
      "\n",
      "Epoch: 126 / 200\n",
      "\ttrain:\tloss = 0.056381, acc = 0.977695\n",
      "\ttest:\tloss = 0.040282, acc = 0.984456\n",
      "\tlr=5.00e-06\n",
      "\n",
      "Epoch: 127 / 200\n",
      "\ttrain:\tloss = 0.053516, acc = 0.978934\n",
      "\ttest:\tloss = 0.035634, acc = 0.987047\n",
      "\tlr=5.00e-06\n",
      "\n",
      "Epoch: 128 / 200\n",
      "\ttrain:\tloss = 0.053980, acc = 0.980174\n",
      "\ttest:\tloss = 0.037208, acc = 0.987047\n",
      "\tlr=5.00e-06\n",
      "\n",
      "Epoch: 129 / 200\n",
      "\ttrain:\tloss = 0.054638, acc = 0.980174\n",
      "\ttest:\tloss = 0.036584, acc = 0.984456\n",
      "\tlr=5.00e-06\n",
      "\n",
      "Epoch: 130 / 200\n",
      "\ttrain:\tloss = 0.056229, acc = 0.977695\n",
      "\ttest:\tloss = 0.048803, acc = 0.981865\n",
      "\tlr=5.00e-06\n",
      "\n",
      "Epoch: 131 / 200\n",
      "\ttrain:\tloss = 0.058940, acc = 0.977076\n",
      "\ttest:\tloss = 0.044751, acc = 0.979275\n",
      "\tlr=5.00e-06\n",
      "\n",
      "Epoch: 132 / 200\n",
      "\ttrain:\tloss = 0.056941, acc = 0.979554\n",
      "\ttest:\tloss = 0.032335, acc = 0.992228\n",
      "\tlr=2.50e-06\n",
      "\n",
      "Epoch: 133 / 200\n",
      "\ttrain:\tloss = 0.049304, acc = 0.980793\n",
      "\ttest:\tloss = 0.040179, acc = 0.987047\n",
      "\tlr=2.50e-06\n",
      "\n",
      "Epoch: 134 / 200\n",
      "\ttrain:\tloss = 0.050155, acc = 0.980793\n",
      "\ttest:\tloss = 0.032099, acc = 0.989637\n",
      "\tlr=2.50e-06\n",
      "\n",
      "Epoch: 135 / 200\n",
      "\ttrain:\tloss = 0.055631, acc = 0.979554\n",
      "\ttest:\tloss = 0.030891, acc = 0.989637\n",
      "\tlr=2.50e-06\n",
      "\n",
      "Epoch: 136 / 200\n",
      "\ttrain:\tloss = 0.052409, acc = 0.978315\n",
      "\ttest:\tloss = 0.033806, acc = 0.989637\n",
      "\tlr=2.50e-06\n",
      "\n",
      "Epoch: 137 / 200\n",
      "\ttrain:\tloss = 0.055667, acc = 0.978934\n",
      "\ttest:\tloss = 0.039431, acc = 0.984456\n",
      "\tlr=2.50e-06\n",
      "\n",
      "Epoch: 138 / 200\n",
      "\ttrain:\tloss = 0.054641, acc = 0.978315\n",
      "\ttest:\tloss = 0.040418, acc = 0.981865\n",
      "\tlr=2.50e-06\n",
      "\n",
      "Epoch: 139 / 200\n",
      "\ttrain:\tloss = 0.049443, acc = 0.978315\n",
      "\ttest:\tloss = 0.028097, acc = 0.992228\n",
      "\tlr=2.50e-06\n",
      "\n",
      "Epoch: 140 / 200\n",
      "\ttrain:\tloss = 0.048803, acc = 0.978315\n",
      "\ttest:\tloss = 0.031651, acc = 0.992228\n",
      "\tlr=2.50e-06\n",
      "\n",
      "Epoch: 141 / 200\n",
      "\ttrain:\tloss = 0.049056, acc = 0.980793\n",
      "\ttest:\tloss = 0.032709, acc = 0.987047\n",
      "\tlr=2.50e-06\n",
      "\n",
      "Epoch: 142 / 200\n",
      "\ttrain:\tloss = 0.051275, acc = 0.980174\n",
      "\ttest:\tloss = 0.034249, acc = 0.989637\n",
      "\tlr=2.50e-06\n",
      "\n",
      "Epoch: 143 / 200\n",
      "\ttrain:\tloss = 0.048957, acc = 0.979554\n",
      "\ttest:\tloss = 0.031051, acc = 0.992228\n",
      "\tlr=2.50e-06\n",
      "\n",
      "Epoch: 144 / 200\n",
      "\ttrain:\tloss = 0.050226, acc = 0.977695\n",
      "\ttest:\tloss = 0.034150, acc = 0.989637\n",
      "\tlr=2.50e-06\n",
      "\n",
      "Epoch: 145 / 200\n",
      "\ttrain:\tloss = 0.049047, acc = 0.980793\n",
      "\ttest:\tloss = 0.034645, acc = 0.987047\n",
      "\tlr=2.50e-06\n",
      "\n",
      "Epoch: 146 / 200\n",
      "\ttrain:\tloss = 0.051123, acc = 0.980174\n",
      "\ttest:\tloss = 0.037535, acc = 0.981865\n",
      "\tlr=2.50e-06\n",
      "\n",
      "Epoch: 147 / 200\n",
      "\ttrain:\tloss = 0.051598, acc = 0.975836\n",
      "\ttest:\tloss = 0.041250, acc = 0.987047\n",
      "\tlr=2.50e-06\n",
      "\n",
      "Epoch: 148 / 200\n",
      "\ttrain:\tloss = 0.053459, acc = 0.978934\n",
      "\ttest:\tloss = 0.032579, acc = 0.992228\n",
      "\tlr=2.50e-06\n",
      "\n",
      "Epoch: 149 / 200\n",
      "\ttrain:\tloss = 0.050242, acc = 0.981413\n",
      "\ttest:\tloss = 0.037867, acc = 0.984456\n",
      "\tlr=2.50e-06\n",
      "\n",
      "Epoch: 150 / 200\n",
      "\ttrain:\tloss = 0.045082, acc = 0.980793\n",
      "\ttest:\tloss = 0.033513, acc = 0.984456\n",
      "\tlr=1.25e-06\n",
      "\n",
      "Epoch: 151 / 200\n",
      "\ttrain:\tloss = 0.046107, acc = 0.980793\n",
      "\ttest:\tloss = 0.033518, acc = 0.984456\n",
      "\tlr=1.25e-06\n",
      "\n",
      "Epoch: 152 / 200\n",
      "\ttrain:\tloss = 0.047481, acc = 0.982032\n",
      "\ttest:\tloss = 0.032850, acc = 0.984456\n",
      "\tlr=1.25e-06\n",
      "\n",
      "Epoch: 153 / 200\n",
      "\ttrain:\tloss = 0.048959, acc = 0.978315\n",
      "\ttest:\tloss = 0.031011, acc = 0.989637\n",
      "\tlr=1.25e-06\n",
      "\n",
      "Epoch: 154 / 200\n",
      "\ttrain:\tloss = 0.047290, acc = 0.979554\n",
      "\ttest:\tloss = 0.031570, acc = 0.987047\n",
      "\tlr=1.25e-06\n",
      "\n",
      "Epoch: 155 / 200\n",
      "\ttrain:\tloss = 0.050776, acc = 0.983891\n",
      "\ttest:\tloss = 0.033630, acc = 0.984456\n",
      "\tlr=1.25e-06\n",
      "\n",
      "Epoch: 156 / 200\n",
      "\ttrain:\tloss = 0.050830, acc = 0.983271\n",
      "\ttest:\tloss = 0.033919, acc = 0.987047\n",
      "\tlr=1.25e-06\n",
      "\n",
      "Epoch: 157 / 200\n",
      "\ttrain:\tloss = 0.051144, acc = 0.981413\n",
      "\ttest:\tloss = 2.178393, acc = 0.987047\n",
      "\tlr=1.25e-06\n",
      "\n",
      "Epoch: 158 / 200\n",
      "\ttrain:\tloss = 0.048861, acc = 0.980793\n",
      "\ttest:\tloss = 0.033837, acc = 0.987047\n",
      "\tlr=1.25e-06\n",
      "\n",
      "Epoch: 159 / 200\n",
      "\ttrain:\tloss = 0.046714, acc = 0.978315\n",
      "\ttest:\tloss = 0.034389, acc = 0.984456\n",
      "\tlr=1.25e-06\n",
      "\n",
      "Epoch: 160 / 200\n",
      "\ttrain:\tloss = 0.054574, acc = 0.978315\n",
      "\ttest:\tloss = 0.130148, acc = 0.989637\n",
      "\tlr=1.25e-06\n",
      "\n",
      "Epoch: 161 / 200\n",
      "\ttrain:\tloss = 0.052599, acc = 0.978315\n",
      "\ttest:\tloss = 0.033120, acc = 0.992228\n",
      "\tlr=6.25e-07\n",
      "\n",
      "Epoch: 162 / 200\n",
      "\ttrain:\tloss = 0.046894, acc = 0.978934\n",
      "\ttest:\tloss = 0.034747, acc = 0.987047\n",
      "\tlr=6.25e-07\n",
      "\n",
      "Epoch: 163 / 200\n",
      "\ttrain:\tloss = 0.049484, acc = 0.980793\n",
      "\ttest:\tloss = 0.053836, acc = 0.989637\n",
      "\tlr=6.25e-07\n",
      "\n",
      "Epoch: 164 / 200\n",
      "\ttrain:\tloss = 0.047112, acc = 0.982032\n",
      "\ttest:\tloss = 0.033576, acc = 0.984456\n",
      "\tlr=6.25e-07\n",
      "\n",
      "Epoch: 165 / 200\n",
      "\ttrain:\tloss = 0.048649, acc = 0.982652\n",
      "\ttest:\tloss = 0.034411, acc = 0.984456\n",
      "\tlr=6.25e-07\n",
      "\n",
      "Epoch: 166 / 200\n",
      "\ttrain:\tloss = 0.048477, acc = 0.981413\n",
      "\ttest:\tloss = 0.036157, acc = 0.981865\n",
      "\tlr=6.25e-07\n",
      "\n",
      "Epoch: 167 / 200\n",
      "\ttrain:\tloss = 0.048451, acc = 0.982032\n",
      "\ttest:\tloss = 0.035004, acc = 0.984456\n",
      "\tlr=6.25e-07\n",
      "\n",
      "Epoch: 168 / 200\n",
      "\ttrain:\tloss = 0.049220, acc = 0.981413\n",
      "\ttest:\tloss = 0.034356, acc = 0.987047\n",
      "\tlr=6.25e-07\n",
      "\n",
      "Epoch: 169 / 200\n",
      "\ttrain:\tloss = 0.052226, acc = 0.982652\n",
      "\ttest:\tloss = 0.032172, acc = 0.989637\n",
      "\tlr=6.25e-07\n",
      "\n",
      "Epoch: 170 / 200\n",
      "\ttrain:\tloss = 0.052887, acc = 0.982032\n",
      "\ttest:\tloss = 0.035207, acc = 0.987047\n",
      "\tlr=6.25e-07\n",
      "\n",
      "Epoch: 171 / 200\n",
      "\ttrain:\tloss = 0.052491, acc = 0.980793\n",
      "\ttest:\tloss = 0.036435, acc = 0.987047\n",
      "\tlr=6.25e-07\n",
      "\n",
      "Epoch: 172 / 200\n",
      "\ttrain:\tloss = 0.046534, acc = 0.983271\n",
      "\ttest:\tloss = 0.034594, acc = 0.981865\n",
      "\tlr=3.13e-07\n",
      "\n",
      "Epoch: 173 / 200\n",
      "\ttrain:\tloss = 0.044781, acc = 0.982032\n",
      "\ttest:\tloss = 0.031563, acc = 0.987047\n",
      "\tlr=3.13e-07\n",
      "\n",
      "Epoch: 174 / 200\n",
      "\ttrain:\tloss = 0.046314, acc = 0.980793\n",
      "\ttest:\tloss = 0.034898, acc = 0.984456\n",
      "\tlr=3.13e-07\n",
      "\n",
      "Epoch: 175 / 200\n",
      "\ttrain:\tloss = 0.050836, acc = 0.979554\n",
      "\ttest:\tloss = 0.030736, acc = 0.992228\n",
      "\tlr=3.13e-07\n",
      "\n",
      "Epoch: 176 / 200\n",
      "\ttrain:\tloss = 0.051771, acc = 0.981413\n",
      "\ttest:\tloss = 0.033046, acc = 0.987047\n",
      "\tlr=3.13e-07\n",
      "\n",
      "Epoch: 177 / 200\n",
      "\ttrain:\tloss = 0.046467, acc = 0.982032\n",
      "\ttest:\tloss = 0.037067, acc = 0.984456\n",
      "\tlr=3.13e-07\n",
      "\n",
      "Epoch: 178 / 200\n",
      "\ttrain:\tloss = 0.046580, acc = 0.980793\n",
      "\ttest:\tloss = 0.029857, acc = 0.989637\n",
      "\tlr=3.13e-07\n",
      "\n",
      "Epoch: 179 / 200\n",
      "\ttrain:\tloss = 0.047249, acc = 0.980793\n",
      "\ttest:\tloss = 0.036941, acc = 0.987047\n",
      "\tlr=3.13e-07\n",
      "\n",
      "Epoch: 180 / 200\n",
      "\ttrain:\tloss = 0.049543, acc = 0.980174\n",
      "\ttest:\tloss = 0.035114, acc = 0.984456\n",
      "\tlr=3.13e-07\n",
      "\n",
      "Epoch: 181 / 200\n",
      "\ttrain:\tloss = 0.048209, acc = 0.978934\n",
      "\ttest:\tloss = 0.031928, acc = 0.989637\n",
      "\tlr=3.13e-07\n",
      "\n",
      "Epoch: 182 / 200\n",
      "\ttrain:\tloss = 0.047066, acc = 0.982032\n",
      "\ttest:\tloss = 0.032709, acc = 0.981865\n",
      "\tlr=3.13e-07\n",
      "\n",
      "Epoch: 183 / 200\n",
      "\ttrain:\tloss = 0.049608, acc = 0.979554\n",
      "\ttest:\tloss = 0.031781, acc = 0.981865\n",
      "\tlr=1.56e-07\n",
      "\n",
      "Epoch: 184 / 200\n",
      "\ttrain:\tloss = 0.044822, acc = 0.981413\n",
      "\ttest:\tloss = 0.035230, acc = 0.984456\n",
      "\tlr=1.56e-07\n",
      "\n",
      "Epoch: 185 / 200\n",
      "\ttrain:\tloss = 0.046817, acc = 0.982652\n",
      "\ttest:\tloss = 0.031312, acc = 0.992228\n",
      "\tlr=1.56e-07\n",
      "\n",
      "Epoch: 186 / 200\n",
      "\ttrain:\tloss = 0.049579, acc = 0.981413\n",
      "\ttest:\tloss = 0.032549, acc = 0.984456\n",
      "\tlr=1.56e-07\n",
      "\n",
      "Epoch: 187 / 200\n",
      "\ttrain:\tloss = 0.049398, acc = 0.981413\n",
      "\ttest:\tloss = 0.035274, acc = 0.984456\n",
      "\tlr=1.56e-07\n",
      "\n",
      "Epoch: 188 / 200\n",
      "\ttrain:\tloss = 0.049258, acc = 0.980793\n",
      "\ttest:\tloss = 0.031861, acc = 0.987047\n",
      "\tlr=1.56e-07\n",
      "\n",
      "Epoch: 189 / 200\n",
      "\ttrain:\tloss = 0.045962, acc = 0.982032\n",
      "\ttest:\tloss = 0.032256, acc = 0.987047\n",
      "\tlr=1.56e-07\n",
      "\n",
      "Epoch: 190 / 200\n",
      "\ttrain:\tloss = 0.049431, acc = 0.982032\n",
      "\ttest:\tloss = 0.031543, acc = 0.987047\n",
      "\tlr=1.56e-07\n",
      "\n",
      "Epoch: 191 / 200\n",
      "\ttrain:\tloss = 0.048993, acc = 0.980174\n",
      "\ttest:\tloss = 0.028689, acc = 0.992228\n",
      "\tlr=1.56e-07\n",
      "\n",
      "Epoch: 192 / 200\n",
      "\ttrain:\tloss = 0.047783, acc = 0.982652\n",
      "\ttest:\tloss = 0.031265, acc = 0.989637\n",
      "\tlr=1.56e-07\n",
      "\n",
      "Epoch: 193 / 200\n",
      "\ttrain:\tloss = 0.045946, acc = 0.982652\n",
      "\ttest:\tloss = 0.041096, acc = 0.987047\n",
      "\tlr=1.56e-07\n",
      "\n",
      "Epoch: 194 / 200\n",
      "\ttrain:\tloss = 0.047088, acc = 0.981413\n",
      "\ttest:\tloss = 0.035610, acc = 0.984456\n",
      "\tlr=7.81e-08\n",
      "\n",
      "Epoch: 195 / 200\n",
      "\ttrain:\tloss = 0.044341, acc = 0.982652\n",
      "\ttest:\tloss = 0.035478, acc = 0.989637\n",
      "\tlr=7.81e-08\n",
      "\n",
      "Epoch: 196 / 200\n",
      "\ttrain:\tloss = 0.048821, acc = 0.982032\n",
      "\ttest:\tloss = 0.047933, acc = 0.984456\n",
      "\tlr=7.81e-08\n",
      "\n",
      "Epoch: 197 / 200\n",
      "\ttrain:\tloss = 0.049224, acc = 0.980793\n",
      "\ttest:\tloss = 0.034023, acc = 0.989637\n",
      "\tlr=7.81e-08\n",
      "\n",
      "Epoch: 198 / 200\n",
      "\ttrain:\tloss = 0.044691, acc = 0.983891\n",
      "\ttest:\tloss = 0.032346, acc = 0.987047\n",
      "\tlr=7.81e-08\n",
      "\n",
      "Epoch: 199 / 200\n",
      "\ttrain:\tloss = 0.048258, acc = 0.982652\n",
      "\ttest:\tloss = 0.033235, acc = 0.989637\n",
      "\tlr=7.81e-08\n",
      "\n",
      "Epoch: 200 / 200\n",
      "\ttrain:\tloss = 0.042778, acc = 0.983271\n",
      "\ttest:\tloss = 0.037559, acc = 0.989637\n",
      "\tlr=7.81e-08\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "discriminator = AlexNetCAMD(input_channels=1).cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction='mean')\n",
    "optimizer = torch.optim.Adam(discriminator.parameters(), lr=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=.5, patience=10)\n",
    "\n",
    "def calc_correct(pred, true_class):\n",
    "    pred_class = torch.argmax(pred, dim=1, keepdim=False)\n",
    "    result = torch.sum(pred_class == true_class, dim=0)\n",
    "    return result\n",
    "\n",
    "epochs = 200\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    train_loss, num_correct, total = 0, 0, 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = discriminator(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        num_correct += calc_correct(outputs, labels)\n",
    "        total += len(outputs)\n",
    "        # print(num_correct, total)\n",
    "    \n",
    "    train_loss_avg = train_loss / len(train_loader)\n",
    "    acc = num_correct / total\n",
    "    print(f'\\nEpoch: {epoch + 1} / {epochs}')\n",
    "    print(f'\\ttrain:\\tloss = {train_loss_avg:.6f}, acc = {acc:.6f}')\n",
    "    \n",
    "    test_loss, num_correct, total = 0, 0, 0\n",
    "    for i, data in enumerate(test_loader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = discriminator(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        num_correct += calc_correct(outputs, labels)\n",
    "        total += len(outputs)\n",
    "        \n",
    "    test_loss_avg = test_loss / len(test_loader)\n",
    "    acc = num_correct / total\n",
    "    print(f'\\ttest:\\tloss = {test_loss_avg:.6f}, acc = {acc:.6f}')\n",
    "    \n",
    "    scheduler.step(test_loss_avg)\n",
    "    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        cur_lr = param_group['lr']\n",
    "        break\n",
    "    print(f'\\tlr={cur_lr:.2e}')\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "dataset = f'rnd_crop_{min_signal}'\n",
    "torch.save(discriminator.state_dict(), f'results/{dataset}_model_dict_{plane}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Make sure to run evaluation after all planes are done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data = []\n",
    "# wires = ['U', 'V', 'W']\n",
    "# for layer in wires:\n",
    "#     print(f'{layer}:')\n",
    "    \n",
    "#     # Load data\n",
    "#     class_paths_train = [f'{path_base}/{dataset}{layer}/trainA/', f'{path_base}/{dataset}{layer}/trainB/']\n",
    "#     class_paths_test = [f'{path_base}/{dataset}{layer}/testA/', f'{path_base}/{dataset}{layer}/testB/']\n",
    "#     class_paths_test_d = [f'{path_base}/Dmitrii/{layer}/testA/', f'{path_base}/Dmitrii/{layer}/testB/']\n",
    "\n",
    "#     dataset_train = Dataset_ls4gan(class_paths_train)\n",
    "#     dataset_test = Dataset_ls4gan(class_paths_test)\n",
    "#     dataset_test_d = Dataset_ls4gan(class_paths_test_d)\n",
    "\n",
    "#     train_loader = DataLoader(dataset_train, batch_size=bsz, shuffle=True)\n",
    "#     test_loader = DataLoader(dataset_test, batch_size=bsz, shuffle=True)\n",
    "#     test_loader_d = DataLoader(dataset_test_d, batch_size=bsz, shuffle=True)\n",
    "    \n",
    "#     # Load model\n",
    "#     discriminator = AlexNetCAMD(input_channels=1).cuda()\n",
    "#     discriminator.load_state_dict(torch.load(f'results/{dataset}model_dict_{layer}.pt'))\n",
    "#     discriminator.eval()\n",
    "    \n",
    "#     # Evaluation\n",
    "#     splits = ['train', 'test', 'test_d']\n",
    "#     df_data_row = []\n",
    "#     with torch.no_grad():\n",
    "#         for split, loader in zip(splits, [train_loader, test_loader, test_loader_d]):\n",
    "#             total_example, total_correct = 0, 0\n",
    "#             for i, data in enumerate(loader):\n",
    "#                 inputs, labels = data\n",
    "#                 inputs = inputs.cuda()\n",
    "#                 labels = labels.cuda()\n",
    "#                 pred = discriminator(inputs)\n",
    "\n",
    "#                 pred_class = torch.argmax(pred, dim=1, keepdim=False)\n",
    "#                 result = torch.sum(pred_class == labels, dim=0)\n",
    "#                 total_correct += result\n",
    "#                 total_example += labels.shape[0]\n",
    "\n",
    "#             acc = total_correct / total_example\n",
    "#             print(f'\\t{split} accuracy = {acc:.3f}')\n",
    "#             df_data_row.append(acc.cpu().detach().numpy())\n",
    "#     df_data.append(df_data_row)\n",
    "\n",
    "# df_result = pd.DataFrame(data=df_data, columns=['train', 'test', 'test_d'], index=wires)\n",
    "# df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U:\n",
      "loading files from /hpcgpfs01/scratch/yhuang2/merged/fake\n",
      "loading files from /hpcgpfs01/scratch/yhuang2/merged/real\n",
      "Done!\n",
      "\ttrain accuracy = 0.964\n",
      "\ttest accuracy = 0.969\n",
      "V:\n",
      "loading files from /hpcgpfs01/scratch/yhuang2/merged/fake\n",
      "loading files from /hpcgpfs01/scratch/yhuang2/merged/real\n",
      "Done!\n",
      "\ttrain accuracy = 0.947\n",
      "\ttest accuracy = 0.943\n",
      "W:\n",
      "loading files from /hpcgpfs01/scratch/yhuang2/merged/fake\n",
      "loading files from /hpcgpfs01/scratch/yhuang2/merged/real\n",
      "Done!\n",
      "\ttrain accuracy = 0.744\n",
      "\ttest accuracy = 0.720\n"
     ]
    }
   ],
   "source": [
    "df_data = []\n",
    "planes = ['U', 'V', 'W']\n",
    "for plane in planes:\n",
    "    print(f'{plane}:')\n",
    "\n",
    "    dl = Dataset_ls4gan(\n",
    "        data_path, \n",
    "        window_fname, \n",
    "        num_samples=2000, \n",
    "        planes=[plane], \n",
    "        batch_size=batch_size)\n",
    "    train_loader, test_loader = dl.get_loaders()\n",
    "    \n",
    "    # Load model\n",
    "    discriminator = AlexNetCAMD(input_channels=1).cuda()\n",
    "    discriminator.load_state_dict(torch.load(f'results/{dataset}_model_dict_{plane}.pt'))\n",
    "    discriminator.eval()\n",
    "    \n",
    "    \n",
    "    splits = ['train', 'test']\n",
    "    loaders = [train_loader, test_loader]\n",
    "    \n",
    "    df_data_row = []\n",
    "    with torch.no_grad():\n",
    "        for split, loader in zip(splits, loaders):\n",
    "            total_example, total_correct = 0, 0\n",
    "            for i, data in enumerate(loader):\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "                pred = discriminator(inputs)\n",
    "\n",
    "                pred_class = torch.argmax(pred, dim=1, keepdim=False)\n",
    "                result = torch.sum(pred_class == labels, dim=0)\n",
    "                total_correct += result\n",
    "                total_example += labels.shape[0]\n",
    "\n",
    "            acc = total_correct / total_example\n",
    "            print(f'\\t{split} accuracy = {acc:.3f}')\n",
    "            df_data_row.append(acc.cpu().detach().numpy())\n",
    "    df_data.append(df_data_row)\n",
    "\n",
    "df_result = pd.DataFrame(data=df_data, columns=['train', 'test'], index=planes)    \n",
    "df_result.to_csv(f'results/{dataset}_ACC.csv', float_format='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>50</th>\n",
       "      <th>100</th>\n",
       "      <th>150</th>\n",
       "      <th>200</th>\n",
       "      <th>300</th>\n",
       "      <th>400</th>\n",
       "      <th>500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>U</th>\n",
       "      <td>0.956515</td>\n",
       "      <td>0.983691</td>\n",
       "      <td>0.966575</td>\n",
       "      <td>0.989316</td>\n",
       "      <td>0.985352</td>\n",
       "      <td>0.993539</td>\n",
       "      <td>0.994965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V</th>\n",
       "      <td>0.942852</td>\n",
       "      <td>0.966631</td>\n",
       "      <td>0.944743</td>\n",
       "      <td>0.983256</td>\n",
       "      <td>0.983755</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>0.981171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W</th>\n",
       "      <td>0.639588</td>\n",
       "      <td>0.767759</td>\n",
       "      <td>0.732344</td>\n",
       "      <td>0.730430</td>\n",
       "      <td>0.796185</td>\n",
       "      <td>0.798760</td>\n",
       "      <td>0.782894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         50       100       150       200       300       400       500\n",
       "U  0.956515  0.983691  0.966575  0.989316  0.985352  0.993539  0.994965\n",
       "V  0.942852  0.966631  0.944743  0.983256  0.983755  0.987500  0.981171\n",
       "W  0.639588  0.767759  0.732344  0.730430  0.796185  0.798760  0.782894"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for fname in Path('results').glob('rnd_crop_*_ACC.csv'):\n",
    "    min_signal = int(fname.stem.split('_')[-2])\n",
    "    df = pd.read_csv(fname, index_col=0)\n",
    "    df[f'{min_signal}'] = (df['train'] + df['test']) / 2\n",
    "    dfs.append(df[f'{min_signal}'])\n",
    "df = pd.concat(dfs, axis=1)\n",
    "df = df.reindex(sorted(df.columns, key=lambda x: int(x)), axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yi_test",
   "language": "python",
   "name": "yi_test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
